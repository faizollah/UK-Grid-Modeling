{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Regression**:\n",
        "##Predicting the actual carbon intensity given the forecasted value"
      ],
      "metadata": {
        "id": "LskQJSUt21rR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVni6qo1xuEg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "def fetch_carbon_intensity_data(start_date, end_date):\n",
        "    # Define the URL endpoint\n",
        "    base_url = \"https://api.carbonintensity.org.uk/intensity/\"\n",
        "    url = f\"{base_url}{start_date}/{end_date}\"\n",
        "\n",
        "    # Set the headers\n",
        "    headers = {\n",
        "        'Accept': 'application/json'\n",
        "    }\n",
        "\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error {response.status_code}: {response.text}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the date range (14 days from today)\n",
        "    end_date = datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "    start_date = (datetime.datetime.utcnow() - datetime.timedelta(days=14)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "    # Fetch the data\n",
        "    data = fetch_carbon_intensity_data(start_date, end_date)\n",
        "\n",
        "    # Save the data to a JSON file\n",
        "    if data:\n",
        "        with open('carbon_intensity_data.json', 'w') as file:\n",
        "            json.dump(data, file, indent=4)\n",
        "        print(\"Data saved to 'carbon_intensity_data.json'\")\n",
        "    else:\n",
        "        print(\"Failed to fetch data.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/carbon_intensity_data.json'\n",
        "\n",
        "# Read the JSON file into a DataFrame\n",
        "df = pd.read_json(file_path)\n",
        "\n",
        "# Assuming the data is structured with a 'data' key, extract that into a new DataFrame\n",
        "df = pd.DataFrame(df['data'].tolist())\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzOsayZ6x_Vb",
        "outputId": "c144ed61-4b8c-48ce-adce-f965f2dd37fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  from                 to  \\\n",
            "0    2023-08-07T20:00Z  2023-08-07T20:30Z   \n",
            "1    2023-08-07T20:30Z  2023-08-07T21:00Z   \n",
            "2    2023-08-07T21:00Z  2023-08-07T21:30Z   \n",
            "3    2023-08-07T21:30Z  2023-08-07T22:00Z   \n",
            "4    2023-08-07T22:00Z  2023-08-07T22:30Z   \n",
            "..                 ...                ...   \n",
            "666  2023-08-21T17:00Z  2023-08-21T17:30Z   \n",
            "667  2023-08-21T17:30Z  2023-08-21T18:00Z   \n",
            "668  2023-08-21T18:00Z  2023-08-21T18:30Z   \n",
            "669  2023-08-21T18:30Z  2023-08-21T19:00Z   \n",
            "670  2023-08-21T19:00Z  2023-08-21T19:30Z   \n",
            "\n",
            "                                             intensity  \n",
            "0    {'forecast': 176, 'actual': 173, 'index': 'mod...  \n",
            "1    {'forecast': 174, 'actual': 177, 'index': 'mod...  \n",
            "2    {'forecast': 172, 'actual': 164, 'index': 'mod...  \n",
            "3    {'forecast': 148, 'actual': 126, 'index': 'mod...  \n",
            "4     {'forecast': 144, 'actual': 110, 'index': 'low'}  \n",
            "..                                                 ...  \n",
            "666  {'forecast': 163, 'actual': 167, 'index': 'mod...  \n",
            "667  {'forecast': 155, 'actual': 174, 'index': 'mod...  \n",
            "668  {'forecast': 158, 'actual': 177, 'index': 'mod...  \n",
            "669  {'forecast': 146, 'actual': 172, 'index': 'mod...  \n",
            "670  {'forecast': 157, 'actual': 170, 'index': 'mod...  \n",
            "\n",
            "[671 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "# 1. Difference between forecasted and actual intensity\n",
        "df['intensity_difference'] = df['intensity'].apply(lambda x: x['forecast'] - x['actual'])\n",
        "\n",
        "# 2. Rolling averages over certain intervals (e.g., 4 intervals which is 2 hours)\n",
        "df['rolling_avg_forecast'] = df['intensity'].apply(lambda x: x['forecast']).rolling(window=4).mean()\n",
        "df['rolling_avg_actual'] = df['intensity'].apply(lambda x: x['actual']).rolling(window=4).mean()\n",
        "\n",
        "# 3. Time-based features\n",
        "df['from_datetime'] = pd.to_datetime(df['from'])\n",
        "df['hour_of_day'] = df['from_datetime'].dt.hour\n",
        "df['day_of_week'] = df['from_datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
        "\n",
        "# Display the DataFrame with the new features\n",
        "print(df[['from', 'intensity_difference', 'rolling_avg_forecast', 'rolling_avg_actual', 'hour_of_day', 'day_of_week']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzz5DMaoyfgN",
        "outputId": "a7097172-3ad9-4996-e6ad-16711b0e4166"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  from  intensity_difference  rolling_avg_forecast  \\\n",
            "0    2023-08-07T20:00Z                     3                   NaN   \n",
            "1    2023-08-07T20:30Z                    -3                   NaN   \n",
            "2    2023-08-07T21:00Z                     8                   NaN   \n",
            "3    2023-08-07T21:30Z                    22                167.50   \n",
            "4    2023-08-07T22:00Z                    34                159.50   \n",
            "..                 ...                   ...                   ...   \n",
            "666  2023-08-21T17:00Z                    -4                129.25   \n",
            "667  2023-08-21T17:30Z                   -19                141.25   \n",
            "668  2023-08-21T18:00Z                   -19                150.50   \n",
            "669  2023-08-21T18:30Z                   -26                155.50   \n",
            "670  2023-08-21T19:00Z                   -13                154.00   \n",
            "\n",
            "     rolling_avg_actual  hour_of_day  day_of_week  \n",
            "0                   NaN           20            0  \n",
            "1                   NaN           20            0  \n",
            "2                   NaN           21            0  \n",
            "3                160.00           21            0  \n",
            "4                144.25           22            0  \n",
            "..                  ...          ...          ...  \n",
            "666              159.00           17            0  \n",
            "667              164.25           17            0  \n",
            "668              169.00           18            0  \n",
            "669              172.50           18            0  \n",
            "670              173.25           19            0  \n",
            "\n",
            "[671 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())\n",
        "df.dropna(inplace=True)\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpqcPtMTzEEI",
        "outputId": "190f4541-196b-49ad-9159-cee16c2231e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from                    0\n",
            "to                      0\n",
            "intensity               0\n",
            "intensity_difference    0\n",
            "rolling_avg_forecast    3\n",
            "rolling_avg_actual      3\n",
            "from_datetime           0\n",
            "hour_of_day             0\n",
            "day_of_week             0\n",
            "dtype: int64\n",
            "from                    0\n",
            "to                      0\n",
            "intensity               0\n",
            "intensity_difference    0\n",
            "rolling_avg_forecast    0\n",
            "rolling_avg_actual      0\n",
            "from_datetime           0\n",
            "hour_of_day             0\n",
            "day_of_week             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the 'index' column\n",
        "index_dummies = pd.get_dummies(df['intensity'].apply(lambda x: x['index']), prefix='index')\n",
        "\n",
        "# Concatenate the one-hot encoded columns to the original dataframe\n",
        "df = pd.concat([df, index_dummies], axis=1)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21JRDI5c5ZPh",
        "outputId": "83b0f887-a6cc-466d-8955-1f62dea909c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['from', 'to', 'intensity', 'intensity_difference',\n",
            "       'rolling_avg_forecast', 'rolling_avg_actual', 'from_datetime',\n",
            "       'hour_of_day', 'day_of_week', 'index_high', 'index_low',\n",
            "       'index_moderate'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data Preparation\n",
        "X = df[['index_moderate', 'index_high', 'index_low']].values\n",
        "y = df['intensity'].apply(lambda x: x['actual']).values\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Building\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=3, activation='relu'))  # Input layer\n",
        "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1, activation='linear'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluation\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Mean Squared Error on Test Set: {loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yWLkLkZzfh3",
        "outputId": "862efbfb-dfdd-4569-fc1e-8676359f46a6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "54/54 [==============================] - 1s 3ms/step - loss: 25461.5059 - val_loss: 23475.2324\n",
            "Epoch 2/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 23721.1973 - val_loss: 20592.4727\n",
            "Epoch 3/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 18367.3867 - val_loss: 13004.5898\n",
            "Epoch 4/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 9305.4990 - val_loss: 4093.7837\n",
            "Epoch 5/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 2343.5190 - val_loss: 649.2773\n",
            "Epoch 6/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 562.5019 - val_loss: 484.6105\n",
            "Epoch 7/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 431.1927 - val_loss: 489.0777\n",
            "Epoch 8/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.9384 - val_loss: 486.1584\n",
            "Epoch 9/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.1844 - val_loss: 491.2775\n",
            "Epoch 10/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.7518 - val_loss: 486.0316\n",
            "Epoch 11/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.8542 - val_loss: 488.7462\n",
            "Epoch 12/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.2679 - val_loss: 486.8969\n",
            "Epoch 13/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.1288 - val_loss: 486.1364\n",
            "Epoch 14/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.1623 - val_loss: 483.6545\n",
            "Epoch 15/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.8817 - val_loss: 490.1159\n",
            "Epoch 16/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.5801 - val_loss: 488.6784\n",
            "Epoch 17/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5732 - val_loss: 487.0295\n",
            "Epoch 18/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.0952 - val_loss: 487.2893\n",
            "Epoch 19/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.7754 - val_loss: 484.2215\n",
            "Epoch 20/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.4011 - val_loss: 487.8845\n",
            "Epoch 21/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.0520 - val_loss: 484.8959\n",
            "Epoch 22/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.5558 - val_loss: 498.6070\n",
            "Epoch 23/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5753 - val_loss: 490.7195\n",
            "Epoch 24/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.3698 - val_loss: 495.0291\n",
            "Epoch 25/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5210 - val_loss: 486.7227\n",
            "Epoch 26/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.8276 - val_loss: 480.3123\n",
            "Epoch 27/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.2593 - val_loss: 486.3074\n",
            "Epoch 28/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.9921 - val_loss: 487.1908\n",
            "Epoch 29/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.4817 - val_loss: 493.3985\n",
            "Epoch 30/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.7727 - val_loss: 489.8611\n",
            "Epoch 31/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.2438 - val_loss: 486.0276\n",
            "Epoch 32/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.1588 - val_loss: 489.2210\n",
            "Epoch 33/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.3259 - val_loss: 495.4148\n",
            "Epoch 34/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.6324 - val_loss: 481.7117\n",
            "Epoch 35/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.0601 - val_loss: 503.5426\n",
            "Epoch 36/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.7394 - val_loss: 480.5111\n",
            "Epoch 37/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.2760 - val_loss: 499.8805\n",
            "Epoch 38/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.9549 - val_loss: 482.5819\n",
            "Epoch 39/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.1647 - val_loss: 489.3014\n",
            "Epoch 40/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5072 - val_loss: 493.0040\n",
            "Epoch 41/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.5555 - val_loss: 481.4743\n",
            "Epoch 42/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.3570 - val_loss: 483.5009\n",
            "Epoch 43/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.4815 - val_loss: 486.9267\n",
            "Epoch 44/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 424.8937 - val_loss: 491.1742\n",
            "Epoch 45/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5928 - val_loss: 485.2469\n",
            "Epoch 46/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.5508 - val_loss: 486.9647\n",
            "Epoch 47/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.8844 - val_loss: 503.1374\n",
            "Epoch 48/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.0131 - val_loss: 483.9709\n",
            "Epoch 49/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.6605 - val_loss: 487.5680\n",
            "Epoch 50/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.8342 - val_loss: 483.7842\n",
            "Epoch 51/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.0627 - val_loss: 480.8109\n",
            "Epoch 52/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.4793 - val_loss: 482.1988\n",
            "Epoch 53/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.3710 - val_loss: 496.0661\n",
            "Epoch 54/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5154 - val_loss: 483.9882\n",
            "Epoch 55/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.0772 - val_loss: 481.4236\n",
            "Epoch 56/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.5313 - val_loss: 493.1097\n",
            "Epoch 57/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.8242 - val_loss: 491.2458\n",
            "Epoch 58/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 431.5734 - val_loss: 489.8565\n",
            "Epoch 59/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.3227 - val_loss: 486.8691\n",
            "Epoch 60/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.3135 - val_loss: 484.4356\n",
            "Epoch 61/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.1059 - val_loss: 483.7523\n",
            "Epoch 62/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.2972 - val_loss: 503.1372\n",
            "Epoch 63/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.5224 - val_loss: 486.6545\n",
            "Epoch 64/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.4850 - val_loss: 479.6188\n",
            "Epoch 65/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.8010 - val_loss: 484.6264\n",
            "Epoch 66/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.6662 - val_loss: 487.6571\n",
            "Epoch 67/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.2966 - val_loss: 482.7914\n",
            "Epoch 68/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.5432 - val_loss: 481.8876\n",
            "Epoch 69/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 431.5903 - val_loss: 482.1761\n",
            "Epoch 70/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.3749 - val_loss: 485.1048\n",
            "Epoch 71/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.6812 - val_loss: 482.9172\n",
            "Epoch 72/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.6001 - val_loss: 516.3001\n",
            "Epoch 73/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 431.6213 - val_loss: 503.1462\n",
            "Epoch 74/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.1678 - val_loss: 482.0786\n",
            "Epoch 75/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.1455 - val_loss: 503.3231\n",
            "Epoch 76/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.9802 - val_loss: 483.4757\n",
            "Epoch 77/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.8301 - val_loss: 490.5354\n",
            "Epoch 78/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 426.7197 - val_loss: 493.0328\n",
            "Epoch 79/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.8390 - val_loss: 493.0966\n",
            "Epoch 80/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.4449 - val_loss: 482.7392\n",
            "Epoch 81/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.4491 - val_loss: 481.3809\n",
            "Epoch 82/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.0014 - val_loss: 486.6654\n",
            "Epoch 83/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.0371 - val_loss: 494.6995\n",
            "Epoch 84/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.4665 - val_loss: 480.6220\n",
            "Epoch 85/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 425.1092 - val_loss: 505.8637\n",
            "Epoch 86/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.1281 - val_loss: 499.8250\n",
            "Epoch 87/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.6560 - val_loss: 485.3216\n",
            "Epoch 88/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.8102 - val_loss: 485.4605\n",
            "Epoch 89/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.1798 - val_loss: 490.9300\n",
            "Epoch 90/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.9936 - val_loss: 492.3697\n",
            "Epoch 91/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.4033 - val_loss: 500.3130\n",
            "Epoch 92/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 431.3870 - val_loss: 480.2374\n",
            "Epoch 93/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.3589 - val_loss: 492.3608\n",
            "Epoch 94/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.4329 - val_loss: 487.8697\n",
            "Epoch 95/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.5912 - val_loss: 490.2758\n",
            "Epoch 96/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 428.8768 - val_loss: 489.6191\n",
            "Epoch 97/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.9451 - val_loss: 501.9784\n",
            "Epoch 98/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 429.4276 - val_loss: 490.5331\n",
            "Epoch 99/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 427.6028 - val_loss: 488.3589\n",
            "Epoch 100/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 430.6823 - val_loss: 504.8270\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 504.8269\n",
            "Mean Squared Error on Test Set: 504.826904296875\n"
          ]
        }
      ]
    }
  ]
}